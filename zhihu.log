2014-10-21 11:08:42+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:08:42+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:08:42+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:08:42+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:08:42+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:08:42+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:08:42+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:08:42+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:08:42+0800 [zhihu_user] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:09:10+0800 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2014-10-21 11:09:10+0800 [zhihu_user] INFO: Closing spider (shutdown)
2014-10-21 11:09:10+0800 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2014-10-21 11:09:31+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:09:31+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:09:31+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:09:31+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:09:31+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:09:31+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:09:31+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:09:31+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:09:31+0800 [zhihu_user] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:10:31+0800 [zhihu_user] INFO: Crawled 17 pages (at 17 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:11:31+0800 [zhihu_user] INFO: Crawled 33 pages (at 16 pages/min), scraped 12 items (at 12 items/min)
2014-10-21 11:12:23+0800 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2014-10-21 11:12:23+0800 [zhihu_user] INFO: Closing spider (shutdown)
2014-10-21 11:12:23+0800 [zhihu_user] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 21965,
	 'downloader/request_count': 48,
	 'downloader/request_method_count/GET': 48,
	 'downloader/response_bytes': 293112,
	 'downloader/response_count': 48,
	 'downloader/response_status_count/200': 48,
	 'finish_reason': 'shutdown',
	 'finish_time': datetime.datetime(2014, 10, 21, 3, 12, 23, 600467),
	 'item_scraped_count': 12,
	 'log_count/INFO': 10,
	 'response_received_count': 48,
	 'scheduler/dequeued/redis': 48,
	 'start_time': datetime.datetime(2014, 10, 21, 3, 9, 31, 765131)}
2014-10-21 11:12:23+0800 [zhihu_user] INFO: Spider closed (shutdown)
2014-10-21 11:12:30+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:12:30+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:12:30+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:12:30+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:12:30+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:12:30+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:12:30+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:12:30+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:12:30+0800 [zhihu_user] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:12:48+0800 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2014-10-21 11:12:48+0800 [zhihu_user] INFO: Closing spider (shutdown)
2014-10-21 11:12:48+0800 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2014-10-21 11:12:49+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:12:49+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:12:49+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:12:49+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:12:49+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:12:49+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:12:49+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:12:49+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:12:49+0800 [zhihu_user] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:13:49+0800 [zhihu_user] INFO: Crawled 17 pages (at 17 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:14:49+0800 [zhihu_user] INFO: Crawled 32 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:15:19+0800 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2014-10-21 11:15:19+0800 [zhihu_user] INFO: Closing spider (shutdown)
2014-10-21 11:15:19+0800 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2014-10-21 11:15:20+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:15:20+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:15:20+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:15:20+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:15:20+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:15:20+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:15:20+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:15:20+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:15:20+0800 [zhihu_user] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:15:38+0800 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2014-10-21 11:15:38+0800 [zhihu_user] INFO: Closing spider (shutdown)
2014-10-21 11:15:38+0800 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2014-10-21 11:17:20+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:17:20+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:17:20+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:17:20+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:17:20+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:17:20+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:17:20+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:17:20+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:17:20+0800 [zhihu_user] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:18:20+0800 [zhihu_user] INFO: Crawled 17 pages (at 17 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:19:20+0800 [zhihu_user] INFO: Crawled 34 pages (at 17 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:19:25+0800 [-] Unhandled Error
	Traceback (most recent call last):
	  File "/usr/lib/pymodules/python2.7/scrapy/crawler.py", line 93, in start
	    self.start_reactor()
	  File "/usr/lib/pymodules/python2.7/scrapy/crawler.py", line 130, in start_reactor
	    reactor.run(installSignalHandlers=False)  # blocking call
	  File "/usr/lib/python2.7/dist-packages/twisted/internet/base.py", line 1192, in run
	    self.mainLoop()
	  File "/usr/lib/python2.7/dist-packages/twisted/internet/base.py", line 1201, in mainLoop
	    self.runUntilCurrent()
	--- <exception caught here> ---
	  File "/usr/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/lib/pymodules/python2.7/scrapy/utils/reactor.py", line 41, in __call__
	    return self._func(*self._a, **self._kw)
	  File "/usr/lib/pymodules/python2.7/scrapy/core/engine.py", line 107, in _next_request
	    if not self._next_request_from_scheduler(spider):
	  File "/usr/lib/pymodules/python2.7/scrapy/core/engine.py", line 134, in _next_request_from_scheduler
	    request = slot.scheduler.next_request()
	  File "/usr/local/lib/python2.7/dist-packages/scrapy_redis/scheduler.py", line 82, in next_request
	    request = self.queue.pop(block_pop_timeout)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy_redis/queue.py", line 94, in pop
	    results, count = pipe.execute()
	  File "/usr/local/lib/python2.7/dist-packages/redis/client.py", line 2593, in execute
	    return execute(conn, stack, raise_on_error)
	  File "/usr/local/lib/python2.7/dist-packages/redis/client.py", line 2447, in _execute_transaction
	    connection.send_packed_command(all_cmds)
	  File "/usr/local/lib/python2.7/dist-packages/redis/connection.py", line 532, in send_packed_command
	    self.connect()
	  File "/usr/local/lib/python2.7/dist-packages/redis/connection.py", line 436, in connect
	    raise ConnectionError(self._error_message(e))
	redis.exceptions.ConnectionError: Error 111 connecting to localhost:6379. Connection refused.
	
2014-10-21 11:19:25+0800 [-] Unhandled Error
	Traceback (most recent call last):
	  File "/usr/lib/pymodules/python2.7/scrapy/crawler.py", line 93, in start
	    self.start_reactor()
	  File "/usr/lib/pymodules/python2.7/scrapy/crawler.py", line 130, in start_reactor
	    reactor.run(installSignalHandlers=False)  # blocking call
	  File "/usr/lib/python2.7/dist-packages/twisted/internet/base.py", line 1192, in run
	    self.mainLoop()
	  File "/usr/lib/python2.7/dist-packages/twisted/internet/base.py", line 1201, in mainLoop
	    self.runUntilCurrent()
	--- <exception caught here> ---
	  File "/usr/lib/python2.7/dist-packages/twisted/internet/base.py", line 824, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/lib/pymodules/python2.7/scrapy/utils/reactor.py", line 41, in __call__
	    return self._func(*self._a, **self._kw)
	  File "/usr/lib/pymodules/python2.7/scrapy/core/engine.py", line 107, in _next_request
	    if not self._next_request_from_scheduler(spider):
	  File "/usr/lib/pymodules/python2.7/scrapy/core/engine.py", line 134, in _next_request_from_scheduler
	    request = slot.scheduler.next_request()
	  File "/usr/local/lib/python2.7/dist-packages/scrapy_redis/scheduler.py", line 82, in next_request
	    request = self.queue.pop(block_pop_timeout)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy_redis/queue.py", line 94, in pop
	    results, count = pipe.execute()
	  File "/usr/local/lib/python2.7/dist-packages/redis/client.py", line 2593, in execute
	    return execute(conn, stack, raise_on_error)
	  File "/usr/local/lib/python2.7/dist-packages/redis/client.py", line 2447, in _execute_transaction
	    connection.send_packed_command(all_cmds)
	  File "/usr/local/lib/python2.7/dist-packages/redis/connection.py", line 532, in send_packed_command
	    self.connect()
	  File "/usr/local/lib/python2.7/dist-packages/redis/connection.py", line 436, in connect
	    raise ConnectionError(self._error_message(e))
	redis.exceptions.ConnectionError: Error 111 connecting to localhost:6379. Connection refused.
	
2014-10-21 11:19:26+0800 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2014-10-21 11:19:26+0800 [zhihu_user] INFO: Closing spider (shutdown)
2014-10-21 11:19:26+0800 [zhihu_user] INFO: Dumping Scrapy stats:
	{'downloader/request_bytes': 21983,
	 'downloader/request_count': 36,
	 'downloader/request_method_count/GET': 36,
	 'downloader/response_bytes': 21996,
	 'downloader/response_count': 36,
	 'downloader/response_status_count/403': 36,
	 'finish_reason': 'shutdown',
	 'finish_time': datetime.datetime(2014, 10, 21, 3, 19, 26, 934637),
	 'log_count/ERROR': 2,
	 'log_count/INFO': 10,
	 'response_received_count': 36,
	 'scheduler/dequeued/redis': 36,
	 'start_time': datetime.datetime(2014, 10, 21, 3, 17, 20, 729106)}
2014-10-21 11:19:26+0800 [zhihu_user] INFO: Spider closed (shutdown)
2014-10-21 11:19:28+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:19:28+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:19:28+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:19:28+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:19:28+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:19:28+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:19:28+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:19:28+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:19:28+0800 [-] ERROR: Unhandled error in Deferred:
2014-10-21 11:19:28+0800 [-] Unhandled Error
	Traceback (most recent call last):
	  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1213, in unwindGenerator
	    return _inlineCallbacks(None, gen, Deferred())
	  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1070, in _inlineCallbacks
	    result = g.send(result)
	  File "/usr/lib/pymodules/python2.7/scrapy/crawler.py", line 66, in start
	    yield self.engine.open_spider(self._spider, self._start_requests())
	  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1213, in unwindGenerator
	    return _inlineCallbacks(None, gen, Deferred())
	--- <exception caught here> ---
	  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 1070, in _inlineCallbacks
	    result = g.send(result)
	  File "/usr/lib/pymodules/python2.7/scrapy/core/engine.py", line 229, in open_spider
	    yield scheduler.open(spider)
	  File "/usr/local/lib/python2.7/dist-packages/scrapy_redis/scheduler.py", line 65, in open
	    if len(self.queue):
	  File "/usr/local/lib/python2.7/dist-packages/scrapy_redis/queue.py", line 77, in __len__
	    return self.server.zcard(self.key)
	  File "/usr/local/lib/python2.7/dist-packages/redis/client.py", line 1578, in zcard
	    return self.execute_command('ZCARD', name)
	  File "/usr/local/lib/python2.7/dist-packages/redis/client.py", line 570, in execute_command
	    connection.send_command(*args)
	  File "/usr/local/lib/python2.7/dist-packages/redis/connection.py", line 556, in send_command
	    self.send_packed_command(self.pack_command(*args))
	  File "/usr/local/lib/python2.7/dist-packages/redis/connection.py", line 532, in send_packed_command
	    self.connect()
	  File "/usr/local/lib/python2.7/dist-packages/redis/connection.py", line 436, in connect
	    raise ConnectionError(self._error_message(e))
	redis.exceptions.ConnectionError: Error 111 connecting to localhost:6379. Connection refused.
	
2014-10-21 11:20:04+0800 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2014-10-21 11:20:04+0800 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2014-10-21 11:20:46+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:20:46+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:20:46+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:20:46+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:20:46+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:20:46+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:20:46+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:20:46+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:20:46+0800 [zhihu_user] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:21:46+0800 [zhihu_user] INFO: Crawled 13 pages (at 13 pages/min), scraped 10 items (at 10 items/min)
2014-10-21 11:22:46+0800 [zhihu_user] INFO: Crawled 29 pages (at 16 pages/min), scraped 26 items (at 16 items/min)
2014-10-21 11:23:46+0800 [zhihu_user] INFO: Crawled 45 pages (at 16 pages/min), scraped 41 items (at 15 items/min)
2014-10-21 11:24:09+0800 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2014-10-21 11:24:09+0800 [zhihu_user] INFO: Closing spider (shutdown)
2014-10-21 11:24:09+0800 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2014-10-21 11:25:45+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:25:45+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:25:45+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:25:45+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:25:45+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:25:45+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:25:45+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:25:45+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:25:45+0800 [zhihu_user] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:26:55+0800 [zhihu_user] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:26:59+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:26:59+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:26:59+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:26:59+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:26:59+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:26:59+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:26:59+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:26:59+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:26:59+0800 [zhihu_user] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:27:59+0800 [zhihu_user] INFO: Crawled 10 pages (at 10 pages/min), scraped 4 items (at 4 items/min)
2014-10-21 11:28:59+0800 [zhihu_user] INFO: Crawled 18 pages (at 8 pages/min), scraped 4 items (at 0 items/min)
2014-10-21 11:29:59+0800 [zhihu_user] INFO: Crawled 26 pages (at 8 pages/min), scraped 4 items (at 0 items/min)
2014-10-21 11:30:59+0800 [zhihu_user] INFO: Crawled 36 pages (at 10 pages/min), scraped 4 items (at 0 items/min)
2014-10-21 11:31:59+0800 [zhihu_user] INFO: Crawled 52 pages (at 16 pages/min), scraped 4 items (at 0 items/min)
2014-10-21 11:32:59+0800 [zhihu_user] INFO: Crawled 66 pages (at 14 pages/min), scraped 4 items (at 0 items/min)
2014-10-21 11:33:59+0800 [zhihu_user] INFO: Crawled 83 pages (at 17 pages/min), scraped 4 items (at 0 items/min)
2014-10-21 11:34:59+0800 [zhihu_user] INFO: Crawled 101 pages (at 18 pages/min), scraped 4 items (at 0 items/min)
2014-10-21 11:35:21+0800 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2014-10-21 11:35:21+0800 [zhihu_user] INFO: Closing spider (shutdown)
2014-10-21 11:35:22+0800 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2014-10-21 11:35:23+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:35:23+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:35:23+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:35:23+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:35:23+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:35:23+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:35:23+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:35:23+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:35:23+0800 [zhihu_user] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:35:43+0800 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2014-10-21 11:35:43+0800 [zhihu_user] INFO: Closing spider (shutdown)
2014-10-21 11:35:43+0800 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2014-10-21 11:35:47+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:35:47+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:35:47+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:35:47+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:35:47+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:35:47+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:35:47+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:35:47+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:35:47+0800 [zhihu_user] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:36:25+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:36:25+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:36:25+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:36:25+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:36:25+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:36:25+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:36:25+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:36:25+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:36:25+0800 [zhihu_user] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:36:33+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:36:33+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:36:33+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:36:33+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:36:33+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:36:33+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:36:33+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:36:36+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:36:36+0800 [zhihu_user] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:37:20+0800 [scrapy] INFO: Scrapy 0.24.4 started (bot: zhihu)
2014-10-21 11:37:20+0800 [scrapy] INFO: Optional features available: ssl, http11
2014-10-21 11:37:20+0800 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'zhihu.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 1, 'RETRY_ENABLED': False, 'SPIDER_MODULES': ['zhihu.spiders'], 'BOT_NAME': 'zhihu', 'DOWNLOAD_TIMEOUT': 15, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'zhihu.log', 'DOWNLOAD_DELAY': 3}
2014-10-21 11:37:20+0800 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState
2014-10-21 11:37:20+0800 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, CustomUserAgentMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-10-21 11:37:20+0800 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-10-21 11:37:20+0800 [scrapy] INFO: Enabled item pipelines: RedisPipeline, MongoDBPipeline
2014-10-21 11:37:20+0800 [zhihu_user] INFO: Spider opened
2014-10-21 11:37:20+0800 [zhihu_user] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-10-21 11:38:20+0800 [zhihu_user] INFO: Crawled 14 pages (at 14 pages/min), scraped 11 items (at 11 items/min)
